{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Set up environment","metadata":{}},{"cell_type":"code","source":"import math, re, os\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport math\nimport random\nimport cv2\nimport urllib\nfrom functools import partial\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(\"Tensorflow version \" + tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:27:29.834492Z","iopub.execute_input":"2021-10-26T13:27:29.834939Z","iopub.status.idle":"2021-10-26T13:27:34.280586Z","shell.execute_reply.started":"2021-10-26T13:27:29.834852Z","shell.execute_reply":"2021-10-26T13:27:34.279719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set up environment and variables","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 64\nCLASSES = ['crack', 'non crack']\nEPOCHS = 100","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:27:34.282256Z","iopub.execute_input":"2021-10-26T13:27:34.28249Z","iopub.status.idle":"2021-10-26T13:27:34.28989Z","shell.execute_reply.started":"2021-10-26T13:27:34.282458Z","shell.execute_reply":"2021-10-26T13:27:34.289187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define data loading methods","metadata":{}},{"cell_type":"code","source":"TRAINING_FILENAMES = tf.io.gfile.glob('../input/vgg-skz-crack-dataset/train/*/*.jpg')\nVALID_FILENAMES = tf.io.gfile.glob('../input/vgg-skz-crack-dataset/validation/*/*.jpg')\nTEST_FILENAMES = tf.io.gfile.glob('../input/vgg-skz-crack-dataset/test/*/*.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:27:34.291011Z","iopub.execute_input":"2021-10-26T13:27:34.291363Z","iopub.status.idle":"2021-10-26T13:27:39.538524Z","shell.execute_reply.started":"2021-10-26T13:27:34.291331Z","shell.execute_reply":"2021-10-26T13:27:39.53773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Augmentation methods (adding random noise to the image)","metadata":{}},{"cell_type":"code","source":"def add_noise(image):\n    VARIABILITY = 60\n    deviation = VARIABILITY*random.random()\n    noise = np.random.normal(0, deviation, image.shape)\n    image += noise\n    np.clip(image, 0., 255.)\n    return image","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:27:39.541587Z","iopub.execute_input":"2021-10-26T13:27:39.542088Z","iopub.status.idle":"2021-10-26T13:27:39.546896Z","shell.execute_reply.started":"2021-10-26T13:27:39.542048Z","shell.execute_reply":"2021-10-26T13:27:39.546287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ndef get_training_dataset():\n    dataset = train_datagen.flow_from_directory(\n        '../input/vgg-skz-crack-dataset/train',\n        class_mode='categorical',\n        target_size=[256, 256],\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n    )\n    \n    return dataset\n\n\nvalid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ndef get_validation_dataset():\n    dataset = valid_datagen.flow_from_directory(\n        '../input/vgg-skz-crack-dataset/validation',\n        class_mode='categorical',\n        target_size=[256, 256],\n        batch_size=BATCH_SIZE,\n    )\n    \n    return dataset\n\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\ndef get_test_dataset():\n    dataset = test_datagen.flow_from_directory(\n        '../input/vgg-skz-crack-dataset/test',\n        target_size=[256, 256],\n        batch_size=BATCH_SIZE,\n    )\n    \n    return dataset\n\ntest2_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ndef count_data_items(filenames):\n    return len(filenames)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:27:39.548624Z","iopub.execute_input":"2021-10-26T13:27:39.549078Z","iopub.status.idle":"2021-10-26T13:27:39.561389Z","shell.execute_reply.started":"2021-10-26T13:27:39.549041Z","shell.execute_reply":"2021-10-26T13:27:39.560749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n\nprint('Dataset: {} training images, {} validation images, {} test images'.format(\n    NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:27:39.563093Z","iopub.execute_input":"2021-10-26T13:27:39.563414Z","iopub.status.idle":"2021-10-26T13:27:39.573463Z","shell.execute_reply.started":"2021-10-26T13:27:39.563301Z","shell.execute_reply":"2021-10-26T13:27:39.572548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# numpy and matplotlib defaults\nnp.set_printoptions(threshold=15, linewidth=80)\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[int(label)], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_image(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image.astype('uint8'))\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n\ndef display_batch_of_images(directory_iterator, predictions=None):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n    # data\n    images, labels = directory_iterator.next()\n    labels = np.argmax(labels, axis=-1)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)//rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[int(label)]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], int(label))\n        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        subplot = display_one_image(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:27:39.574932Z","iopub.execute_input":"2021-10-26T13:27:39.575447Z","iopub.status.idle":"2021-10-26T13:27:39.593738Z","shell.execute_reply.started":"2021-10-26T13:27:39.575413Z","shell.execute_reply":"2021-10-26T13:27:39.592973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_train = get_training_dataset()\nds_valid = get_validation_dataset()\ndisplay_batch_of_images(ds_train)\ndisplay_batch_of_images(ds_valid)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:27:39.595115Z","iopub.execute_input":"2021-10-26T13:27:39.595405Z","iopub.status.idle":"2021-10-26T13:27:53.276888Z","shell.execute_reply.started":"2021-10-26T13:27:39.595372Z","shell.execute_reply":"2021-10-26T13:27:53.276242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the model","metadata":{}},{"cell_type":"markdown","source":"### Learning rate schedule","metadata":{}},{"cell_type":"code","source":"lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-5, \n    decay_steps=10000, \n    decay_rate=0.9)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:27:53.278002Z","iopub.execute_input":"2021-10-26T13:27:53.278431Z","iopub.status.idle":"2021-10-26T13:27:53.284773Z","shell.execute_reply.started":"2021-10-26T13:27:53.278392Z","shell.execute_reply":"2021-10-26T13:27:53.283496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building the model with pretrained ResNet50 model","metadata":{}},{"cell_type":"code","source":"# img_adjust_layer = tf.keras.layers.Lambda(tf.keras.applications.resnet50.preprocess_input, input_shape=[0, *IMAGE_SIZE, 3])\nfrom tensorflow.python.ops.numpy_ops import np_config\nnp_config.enable_numpy_behavior()\n\n\nbase_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, pooling='avg')\nbase_model.trainable = False\n\nmodel = tf.keras.Sequential([\n    # Base\n    base_model,\n    \n    # Head\n#     tf.keras.layers.Flatten()\n    tf.keras.layers.Dense(128, activation='linear'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(2, activation='softmax')  \n])\n\nmodel.summary()\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler, epsilon=0.001),\n    loss='categorical_crossentropy',  \n    metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:27:53.287616Z","iopub.execute_input":"2021-10-26T13:27:53.287926Z","iopub.status.idle":"2021-10-26T13:27:58.337507Z","shell.execute_reply.started":"2021-10-26T13:27:53.287857Z","shell.execute_reply":"2021-10-26T13:27:58.336703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the model","metadata":{}},{"cell_type":"code","source":"early_stopping_callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:27:58.338813Z","iopub.execute_input":"2021-10-26T13:27:58.339106Z","iopub.status.idle":"2021-10-26T13:27:58.344331Z","shell.execute_reply.started":"2021-10-26T13:27:58.339059Z","shell.execute_reply":"2021-10-26T13:27:58.343256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nVALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE\n\nhistory = model.fit(ds_train, \n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    epochs=EPOCHS,\n                    validation_data=ds_valid,\n                    validation_steps=VALID_STEPS,\n                    callbacks=[early_stopping_callbacks]\n                )","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:27:58.345723Z","iopub.execute_input":"2021-10-26T13:27:58.346Z","iopub.status.idle":"2021-10-26T13:28:44.669716Z","shell.execute_reply.started":"2021-10-26T13:27:58.345948Z","shell.execute_reply":"2021-10-26T13:28:44.668557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating model","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\n\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:28:44.671118Z","iopub.status.idle":"2021-10-26T13:28:44.671777Z","shell.execute_reply.started":"2021-10-26T13:28:44.671507Z","shell.execute_reply":"2021-10-26T13:28:44.671546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save the model","metadata":{}},{"cell_type":"code","source":"model.save('./crack_detection_resnet50_model')","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:28:44.67298Z","iopub.status.idle":"2021-10-26T13:28:44.673756Z","shell.execute_reply.started":"2021-10-26T13:28:44.673381Z","shell.execute_reply":"2021-10-26T13:28:44.67341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the model","metadata":{}},{"cell_type":"code","source":"# model = tf.keras.models.load_model(\"../input/resnet-new-crack-detection/crack_detection_resnet50_model\")","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:28:44.674992Z","iopub.status.idle":"2021-10-26T13:28:44.675702Z","shell.execute_reply.started":"2021-10-26T13:28:44.67546Z","shell.execute_reply":"2021-10-26T13:28:44.675487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run predictions","metadata":{}},{"cell_type":"code","source":"ds_test = get_test_dataset()\nSTEP_SIZE_TEST = ds_test.n // ds_test.batch_size\nds_test.reset()\nprobabilities = model.predict(ds_test, steps=STEP_SIZE_TEST, verbose=1)\npredictions = np.argmax(probabilities, axis=-1)\n\ndisplay_batch_of_images(ds_test, predictions)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:28:44.677078Z","iopub.status.idle":"2021-10-26T13:28:44.67775Z","shell.execute_reply.started":"2021-10-26T13:28:44.67751Z","shell.execute_reply":"2021-10-26T13:28:44.677543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Run prediction on whole image","metadata":{}},{"cell_type":"code","source":"def predict_on_crops(input_image, https=False, height=256, width=256, save_crops = False):\n    if https:\n        req = urllib.request.urlopen(input_image)\n        arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n        im = cv2.imdecode(arr, -1)\n    else:\n        im = cv2.imread(input_image)\n        \n    try:\n        imgheight, imgwidth, channels = im.shape\n    except:\n        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n        imgheight, imgwidth, channels = im.shape\n    k=0\n    output_image = np.zeros_like(im)\n    for i in range(0,imgheight,height):\n        for j in range(0,imgwidth,width):\n            a = im[i:i+height, j:j+width]\n            a = np.expand_dims(a, axis=0)\n            processed_a = test2_datagen.flow(a).next()\n            ## discard image cropss that are not full size\n            predicted_class = CLASSES[int(np.argmax(model.predict(processed_a), axis=-1))]\n            ## save image\n            file, ext = os.path.splitext(input_image)\n            image_name = file.split('/')[-1]\n            folder_name = 'out_' + image_name\n            ## Put predicted class on the image\n            if predicted_class == 'crack':\n                color = (0,0, 255)\n            else:\n                color = (0, 255, 0)\n            cv2.putText(a, predicted_class, (50,50), cv2.FONT_HERSHEY_SIMPLEX , 0.7, color, 1, cv2.LINE_AA) \n            b = np.zeros_like(a, dtype=np.uint8)\n            b[:] = color\n            add_img = cv2.addWeighted(a, 0.9, b, 0.1, 0, dtype=cv2.CV_64F)\n            ## Save crops\n            if save_crops:\n                if not os.path.exists(os.path.join('predictions', folder_name)):\n                    os.makedirs(os.path.join('predictions', folder_name))\n                filename = os.path.join('predictions', folder_name,'img_{}.png'.format(k))\n                cv2.imwrite(filename, add_img)\n            output_image[i:i+height, j:j+width,:] = add_img\n            k+=1\n    ## Save output image\n    cv2.imwrite(os.path.join('predictions', folder_name+ '.jpg'), output_image)\n    \n    plt.figure(figsize=(10,10))\n    plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:28:44.679098Z","iopub.status.idle":"2021-10-26T13:28:44.679787Z","shell.execute_reply.started":"2021-10-26T13:28:44.679501Z","shell.execute_reply":"2021-10-26T13:28:44.679528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_on_crops('../input/crack-test/test_big/00001.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:28:44.681109Z","iopub.status.idle":"2021-10-26T13:28:44.681742Z","shell.execute_reply.started":"2021-10-26T13:28:44.681504Z","shell.execute_reply":"2021-10-26T13:28:44.68153Z"},"trusted":true},"execution_count":null,"outputs":[]}]}